# -----------------------------------------------------------------------------
# DEFAULT CONFIGURATION TEMPLATE FOR THE TRAINING PIPELINE (COMPLETE)
# -----------------------------------------------------------------------------
# This file defines all default parameters for the framework, based on the
# recommended settings from the original research.
# A user can override any of these settings in their own `config.yaml` file.
#
# Sections marked as (USER MUST PROVIDE) are placeholders and must be defined
# in the user's config.yaml.

# ---
# SECTION 1: Pipeline & Data Settings
# ---
# (USER MUST PROVIDE in their config.yaml)
pipeline:
  output_dir: null # E.g., "training_output"
  model_checkpoint_path: null # E.g., "training_output/indra_sat_diff/checkpoints/indra_sat_diff_final.pt"

preprocess:
  input_dir: null # E.g., "raw_data"
  output_dir: null # E.g., "processed_data"
  lat_range: null # E.g., [5, 17.8]
  lon_range: null # E.g., [71, 83.8]
  raw_data_coordinate_order: ['lon', 'lat']

data:
  path: null # E.g., "processed_data"
  channels: null # E.g., ['Grid/precipitation']
  latitude_variable_name: 'Grid/lat'
  longitude_variable_name: 'Grid/lon'
  time_variable_name: 'Grid/time'
  time_interval_minutes: 30
  shuffle: true
  num_workers: 8
  val_ratio: 0.05
  test_ratio: 0.05
  metrics_mode: "1"
  metrics_list: ['csi', 'pod', 'sucr', 'bias', 'fss']
  threshold_list: [2.5, 7.6, 16.0, 50.0]

# ---
# SECTION 2: Model & Tensor Layout
# ---
# (USER MUST PROVIDE in their config.yaml)
layout:
  in_len: 7
  out_len: 6
  img_height: 128
  img_width: 128
  layout: "NTHWC"

# ---
# SECTION 3: Training & Optimization Settings
# ---
optim:
  total_batch_size: 16
  micro_batch_size: 2
  max_epochs: 50
  method: "adamw"
  lr: 0.0001
  wd: 0.01
  betas: [0.9, 0.999]
  monitor: "val/loss"
  gradient_clip_val: 1.0

trainer:
  precision: "16-mixed"
  log_every_n_steps: 50

# ---
# SECTION 4: Visualization Settings
# ---
visualization:
  denorm_clip_value: 100.0
  colorbar_label: "Precipitation (mm/hr)"
  boundaries: [0.0, 0.1, 2.5, 7.6, 16.0, 50.0, 100.0]

# =============================================================================
# SECTION 5: MODEL ARCHITECTURE DEFAULTS (Based on Original Research)
# =============================================================================
model:
  # --- VAE Model ---
  vae:
    pretrained_ckpt_path: null # Auto-filled by the training pipeline
    in_channels: 1
    out_channels: 1
    latent_channels: 64
    down_block_types: ['DownEncoderBlock2D', 'DownEncoderBlock2D', 'DownEncoderBlock2D', 'DownEncoderBlock2D']
    up_block_types: ['UpDecoderBlock2D', 'UpDecoderBlock2D', 'UpDecoderBlock2D', 'UpDecoderBlock2D']
    block_out_channels: [128, 256, 512, 512]
    layers_per_block: 2
    act_fn: 'silu'
    norm_num_groups: 32
    loss:
      disc_start: 50001
      kl_weight: 1.0e-6
      disc_weight: 0.5
      perceptual_weight: 0.0
      disc_in_channels: 1

  # --- Alignment Model (NoisyCuboidTransformerEncoder) ---
  align:
    model_ckpt_path: null # Auto-filled by the training pipeline
    alignment_type: "avg_x"
    guide_scale: 50.0
    model_type: "cuboid"
    model_args:
      input_shape: null # Auto-filled by the training pipeline
      out_channels: 1
      base_units: 128
      scale_alpha: 1.0
      depth: [1, 1]
      downsample: 2
      downsample_type: "patch_merge"
      block_attn_patterns: "axial"
      num_heads: 4
      attn_drop: 0.1
      proj_drop: 0.1
      ffn_drop: 0.1
      ffn_activation: "gelu"
      gated_ffn: false
      norm_layer: "layer_norm"
      use_inter_ffn: true
      pos_embed_type: "t+h+w"
      padding_type: "zeros"
      checkpoint_level: 0
      use_relative_pos: true
      self_attn_use_final_proj: true
      num_global_vectors: 0
      use_global_vector_ffn: true
      use_global_self_attn: false
      separate_global_qkv: false
      global_dim_ratio: 1
      time_embed_channels_mult: 4
      time_embed_use_scale_shift_norm: false
      time_embed_dropout: 0.0
      pool: "attention"
      readout_seq: true
      out_len: null # Auto-filled by the training pipeline

  # --- INDRA-Sat-Diff Model (CuboidTransformerUNet) ---
  latent_model:
    input_shape: null # Auto-filled by the training pipeline
    target_shape: null # Auto-filled by the training pipeline
    base_units: 256
    scale_alpha: 1.0
    num_heads: 4
    attn_drop: 0.1
    proj_drop: 0.1
    ffn_drop: 0.1
    downsample: 2
    downsample_type: "patch_merge"
    upsample_type: "upsample"
    upsample_kernel_size: 3
    depth: [4, 4]
    block_attn_patterns: "axial"
    num_global_vectors: 0
    use_global_vector_ffn: false
    use_global_self_attn: true
    separate_global_qkv: true
    global_dim_ratio: 1
    ffn_activation: "gelu"
    gated_ffn: false
    norm_layer: "layer_norm"
    padding_type: "zeros"
    pos_embed_type: "t+h+w"
    checkpoint_level: 0
    use_relative_pos: true
    self_attn_use_final_proj: true
    time_embed_channels_mult: 4
    time_embed_use_scale_shift_norm: false
    time_embed_dropout: 0.0
    unet_res_connect: true

  # --- Diffusion Process ---
  diffusion:
    layout: "NTHWC" # Must match global layout
    data_shape: null # Auto-filled by the training pipeline
    timesteps: 1000
    beta_schedule: "linear"
    use_ema: true
    loss_type: "l2"
    linear_start: 1.0e-4
    linear_end: 2.0e-2
    cosine_s: 8.0e-3
    given_betas: null
    original_elbo_weight: 0.0
    v_posterior: 0.0
    l_simple_weight: 1.0
    parameterization: "eps"
    learn_logvar: false
    logvar_init: 0.0
    latent_shape: null # Auto-filled by the training pipeline
    cond_stage_model: "__is_first_stage__" # Internal flag
    num_timesteps_cond: null
    cond_stage_trainable: false
    cond_stage_forward: null
    scale_by_std: false
    scale_factor: 1.0